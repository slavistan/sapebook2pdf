#!/usr/bin/env sh

# Print usage
usage() {
  cat <<EOF
Generate a PDF from an SAP Learning Hub ebook. Their ebook reader is insulting.

Usage:

  sapebook2pdf COOKIESFILE BASEURL SVGDIR PAGES PDFDIR OUTFILE

      COOKIESFILE is the path to the 'cookies.txt' containing cookies to allow
      access to the ebook's remote files. To acquire a cookies.txt login to
      your account and open the ebook. Use your browser to generate the
      cookies.txt for you (which may require using a plugin).

      BASEURL corresponds to the path containing the ebook's index.html. Given
      'https://sap.com/foo/self-managed/ebook/BC100_EN_Col18/index.html' the
      baseurl is 'https://sap.com/foo/self-managed/ebook/BC100_EN_Col18/'.

      SVGDIR is a temporary directory used to store the ebook's individual
      pages as SVGs files. Directory must exist.

      PAGES shall be a comma-separated list of individual page numbers to
      include in the final PDF. Pages will be generated in order.

      PDFDIR is a temporary directory used to store the ebook's individual
      pages as PDFs files generated from the SVGs. Directory must exist and may
      be the same as SVGDIR.

      OUTFILE shall be the path of the final PDF. The base directory must
      exist.

      The ebooks are stored online as individual pages in SVG format. These
      SVGs reference fonts which are required to be available on your system in
      order for them to end up in the generated PDF. The availability of the
      fonts is checked during compilation with missing fonts having to be
      installed manually on your system. Missing fonts will lead to the usage
      of your system's fallback fonts and may or may not produce a goofy PDF.
      You will be notified about any missing fonts.


    Exemplary usage:

      sapebook2pdf                                                          \\
        ./cookies.txt                                                       \\
        "https://saplearninghub.com/sap/self-managed/ebook/BC100_EN_Col18/" \\
        /tmp/ebook                                                          \\
        "\$(seq -s ',' 1 100)"                                               \\
        /tmp/ebook                                                          \\
        /tmp/ebook/ebook.pdf

      This will download pages 1-100 from the ebook and compile them to a PDF
      saved to /tmp/ebook/ebook.pdf. Note that /tmp/ebook and ./cookies.txt
      must exist.
EOF
}

# Download all SVG files
dlsvgs() {
	cookies="$1" # path to cookies.txt
	baseurl="$2" # head of url to index.html
	outdir="$3" # directory to dl svg files to
	pages="$4" # pages to download as csv

	echo "Downloading SVG files [dlsvg]"

	# Check pages
	if echo "$pages" | grep -q '^[1-9][0-9]*\(,[1-9][0-9]*\)*$'; then
		printf " - [\033[32;1m✔\033[0m] Pages are comma-sep'd list ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Pages are comma-sep'd list ... fail. Abort.\n"
		return 1
	fi

	# Check output directory
	if [ -d "$outdir" ] && [ -w "$outdir" ] &&
		outdir="$(realpath "$outdir")"; then
		printf " - [\033[32;1m✔\033[0m] Output directory is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Output directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Check connection
	printf "\033[2K\r - [ ] Checking connection ... "
	if checkconn "$cookies" "$baseurl" >/dev/null; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Checking connection ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Checking connection ... fail. Abort.\n"
		return 1
	fi

	# Download svg files
	ii=0
	numpgs="$(( 1 + $(echo "$pages" | tr -cd ',' | wc -c) ))"
	errpgs="" # pgnums whose dl failed; csv
	printf "\033[2K\r - [ ] Downloading SVGs ... "
	for pgnum in $(echo "$pages" | tr ',' ' '); do
		pageurl="$baseurl/xml/topic${pgnum}.svg"
		svgpath="$outdir/page${pgnum}.svg"
		ii=$((ii + 1))

		printf "\033[2K\r - [ ] Downloading SVGs ... %d/%d" "$ii" "$numpgs"
		reply="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" "$pageurl")"
		retcode="$(echo "$reply" | tail -n 1)"
		svg="$(echo "$reply" | head -n -1)"

		if [ -z "$svg" ] || [ ! "$retcode" -eq 200 ]; then
			errpgs="${errpgs:+$errpgs,}$pgnum"
		else
			echo "$svg" > "$svgpath"
		fi
	done
	if [ -z "$errpgs" ]; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Downloading SVGs ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Downloading SVGs ... failed for page(s):\n"
		printf "        %s\n" "$errpgs"
		return 1
	fi
}

# Check connection
checkconn() {
	echo "Checking connection [checkconn]"

	# Assert that cookiex.txt exists and is readable
	printf "\033[2K\r - [ ] \033[3mcookies.txt\033[0m exists and is readable ... "
	cookies=""
	if [ -z "$1" ] || ! cookies="$(realpath "$1")" ||
		[ ! -f "$cookies" ] || [ ! -r "$cookies" ]; then
		printf "\033[2K\r - [\033[31;1m✗\033[0m] \033[3mcookies.txt\033[0m is readable ... fail. Abort.\n"
		return 1
	else
		printf "\033[2K\r - [\033[32;1m✔\033[0m] \033[3mcookies.txt\033[0m is readable ... success.\n"
	fi

	# Assert that url is sane
	printf "\033[2K\r - [ ] Baseurl is sane ... "
	baseurl="$2"
	if [ -z "$baseurl" ]; then
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Baseurl is sane ... fail. Abort.\n"
		return 1
	else
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Baseurl is sane ... success.\n"
	fi

	# Attempt to download index.html
	ret=0
	printf "\033[2K\r - [ ] Attempting to download \033[3mindex.html\033[0m ... "
	retcode="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" \
		"$baseurl/index.html" | tail -n -1)"
	if [ "$retcode" -eq 200 ]; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Attempting to download \033[3mindex.html\033[0m ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Attempting to download \033[3mindex.html\033[0m ... fail.\n"
		ret=1
	fi

	# Attempt to download first page
	printf "\033[2K\r - [ ] Attempting to download \033[3mxml/topic1.svg\033[0m ... "
	retcode="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" \
		"$baseurl/xml/topic1.svg" | tail -n -1)"
	if [ "$retcode" -eq 200 ]; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Attempting to download \033[3mxml/topic1.svg\033[0m ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Attempting to download \033[3mxml/topic1.svg\033[0m ... fail.\n"
		ret=1
	fi
	return "$ret"
}

# Check availability of fonts required by SVG files
checkfonts() {
	svgdir="$1"

	echo "Checking fonts [checkfonts]"

	# Check input directory
	if [ -d "$svgdir" ] && [ -w "$svgdir" ] &&
		svgdir="$(realpath "$svgdir")"; then
		printf " - [\033[32;1m✔\033[0m] Input directory is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve svg files in dir
	if svgs="$(find "$svgdir" -maxdepth 1 -mindepth 1 -type f |
		grep '/page[1-9][0-9]*\.svg$')"; then
		numsvgs="$(echo "$svgs" | wc -l)"
		printf " - [\033[32;1m✔\033[0m] Found %d SVG files ... success.\n" "$numsvgs"
	else
		printf " - [\033[31;1m✗\033[0m] No SVG files found ... fail. Abort.\n"
		return 1
	fi

	# Retrieve required and available fonts and compare
	fontsmissing=0
	fontsreq="$(echo "$svgs" | xargs cat | grep -o 'font-family="[^"]*"' |
		cut -d '=' -f 2- | sed -e 's/^"'"'"'\?//g' -e 's/'"'"'\?"$//g' |
		sort | uniq)"
	fontsavail="$(fc-list :family)"
	while read f; do
		if echo "$fontsavail" | grep -q "$f"; then
			printf " - [\033[32;1m✔\033[0m] Font '%s' available.\n" "$f"
		else
			printf " - [\033[31;1m✗\033[0m] Font '%s' not available.\n" "$f"
			fontsmissing=1
		fi
	done <<-EOF
	$fontsreq
	EOF
	return "$fontsmissing"
}

# Generate PDF pages from SVG files
genpdfs() {
	svgdir="$1" # input directory containing page%d.svg files
	pdfdir="$2" # output directory for page%d.pdf files

	echo "Generating PDF pages [genpdfs]"

	# Check input directory
	if [ -d "$svgdir" ] && [ -w "$svgdir" ] &&
		svgdir="$(realpath "$svgdir")"; then
		printf " - [\033[32;1m✔\033[0m] Input directory is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Check output directory
	if [ -d "$pdfdir" ] && [ -w "$pdfdir" ] &&
		pdfdir="$(realpath "$pdfdir")"; then
		printf " - [\033[32;1m✔\033[0m] Output directory is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Output directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve svg files in dir
	if svgs="$(find "$svgdir" -maxdepth 1 -mindepth 1 -type f |
		grep '/page[1-9][0-9]*\.svg$')"; then
		numsvgs="$(echo "$svgs" | wc -l)"
		printf " - [\033[32;1m✔\033[0m] Found %d SVG file(s) ... success.\n" "$numsvgs"
	else
		printf " - [\033[31;1m✗\033[0m] No SVG files found ... fail. Abort.\n"
		return 1
	fi

	ii=0
	errpgs=""
	while read svgfile; do
		pdffile="$pdfdir/$(basename -s '.svg' "$svgfile").pdf"
		ii=$((ii + 1))

		printf "\033[2K\r - [ ] Generating PDF pages from SVGs ... %d/%d" "$ii" "$numpgs"
		# NOTE: We use inkscape for the conversion between SVGs and PDFs.
		#       For unknown reasons 'rsvg-convert', which was used prior to
		#       that, began to distort the images embedded in the SVGs.
		#       Also, see the HACK note below.
		if ! cat "$svgfile" | inkscape --pipe --export-filename="$pdffile" 2>/dev/null; then
		errpgs="${errpgs:+$errpgs, }$svgfile"
		fi
	done <<-EOF
	$svgs
	EOF
	if [ -z "$errpgs" ]; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Generating PDF pages from SVGs ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Generating PDF pages from SVGs  ... failed for page(s):\n"
		printf "        %s\n" "$errpgs"
		return 1
	fi
}

collatepdfs() {
	pdfdir="$1" # input directory containing page%d.png files
	outfile="$2" # output file path for final pdf

	echo "Collating PDF pages [collatepdfs]"

	# Check input directory
	if [ -d "$pdfdir" ] && [ -w "$pdfdir" ] &&
		pdfdir="$(realpath "$pdfdir")"; then
		printf " - [\033[32;1m✔\033[0m] Input directory is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Check output path
	outdir="" # dir containing outfile
	if [ -n "$outfile" ] && outfile="$(realpath "$outfile")" &&
		outdir="$(dirname "$outdir")" && [ -d "$outdir" ] &&
		[ -w "$outdir" ]; then
		printf " - [\033[32;1m✔\033[0m] Output path is accessible ... success.\n"
	else
		printf " - [\033[31;1m✗\033[0m] Output path is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve pdf files in dir (in order)
	if pdfs="$(find "$pdfdir" -maxdepth 1 -mindepth 1 -type f | sort -V |
		grep '/page[1-9][0-9]*\.pdf$')"; then
		numpdfs="$(echo "$pdfs" | wc -l)"
		printf " - [\033[32;1m✔\033[0m] Found %d PDF file(s) ... success.\n" "$numpdfs"
	else
		printf " - [\033[31;1m✗\033[0m] No PDF files found ... fail. Abort.\n"
		return 1
	fi

	# Generate pdf from individual pages
	printf " - [ ] Generating PDF ..."
	if echo "$pdfs" | tr '\n' '\0' |
		xargs -0 sh -c 'pdftk "$@" cat output '"$outfile" "$0" 2>/dev/null; then
		printf "\033[2K\r - [\033[32;1m✔\033[0m] Generating PDF ... success.\n"
	else
		printf "\033[2K\r - [\033[31;1m✗\033[0m] Generating PDF ... fail. Abort.\n"
		return 1
	fi
}

case "$1" in
-h|--help)
	usage
	;;
@)
	shift
	"$@"
	;;
*)
	# HACK: inkscape is terminally stupid and cannot execute cli commands
	#       without an X server. We use Xvfb to entertain inkscape. Note that
	#       we cannot shut down Xvfb safely as multiple instances of this may
	#       be running concurrently. Come back once that's fixed in inkscape.
	if [ -z "$DISPLAY" ]; then
		DISPLAY=:1
		Xvfb $DISPLAY &
	fi

	cookies="$1"
	baseurl="$2"
	svgdir="$3"
	pages="$4"
	pdfdir="$5"
	outfile="$6"

	dlsvgs "$cookies" "$baseurl" "$svgdir" "$pages"
	checkfonts "$svgdir"
	genpdfs "$svgdir" "$pdfdir"
	collatepdfs "$pdfdir" "$outfile"
esac

# TODO: Automatically determine pages
#        - Remove page range parameter
# TODO: Unfuck links (SVGs use javascript "links" by default)
