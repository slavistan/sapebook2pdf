#!/usr/bin/env sh

# Print usage
usage() {
  cat <<EOF
Generate a PDF from an SAP Learning Hub ebook. Their ebook reader is insulting.

Usage:

  sapebook2pdf COOKIESFILE BASEURL SVGDIR PAGES PDFDIR OUTFILE

      COOKIESFILE is the path to the 'cookies.txt' containing cookies to allow
      access to the ebook's remote files. To acquire a cookies.txt login to
      your account and open the ebook. Use your browser to generate the
      cookies.txt for you (which may require using a plugin).

      BASEURL corresponds to the path containing the ebook's index.html. Given
      'https://sap.com/foo/self-managed/ebook/BC100_EN_Col18/index.html' the
      baseurl is 'https://sap.com/foo/self-managed/ebook/BC100_EN_Col18/'.

      SVGDIR is a temporary directory used to store the ebook's individual
      pages as SVGs files. Directory must exist.

      PAGES shall be a comma-separated list of individual page numbers to
      include in the final PDF. Pages will be generated in order.

      PDFDIR is a temporary directory used to store the ebook's individual
      pages as PDFs files generated from the SVGs. Directory must exist and may
      be the same as SVGDIR.

      OUTFILE shall be the path of the final PDF. The base directory must
      exist.

      The ebooks are stored online as individual pages in SVG format. These
      SVGs reference fonts which are required to be available on your system in
      order for them to end up in the generated PDF. The availability of the
      fonts is checked during compilation with missing fonts having to be
      installed manually on your system. Missing fonts will lead to the usage
      of your system's fallback fonts and may or may not produce a goofy PDF.
      You will be notified about any missing fonts.


    Exemplary usage:

      sapebook2pdf                                                          \\
        ./cookies.txt                                                       \\
        "https://saplearninghub.com/sap/self-managed/ebook/BC100_EN_Col18/" \\
        /tmp/ebook                                                          \\
        "\$(seq -s ',' 1 100)"                                               \\
        /tmp/ebook                                                          \\
        /tmp/ebook/ebook.pdf

      This will download pages 1-100 from the ebook and compile them to a PDF
      saved to /tmp/ebook/ebook.pdf. Note that /tmp/ebook and ./cookies.txt
      must exist.
EOF
}

# Download all SVG files
dlsvgs() {
	cookies="$1" # path to cookies.txt
	baseurl="$2" # head of url to index.html
	outdir="$3" # directory to dl svg files to
	pages="$4" # pages to download as csv

	echo "Downloading SVG files [dlsvg]"

	# Check pages
	if echo "$pages" | grep -q '^[1-9][0-9]*\(,[1-9][0-9]*\)*$'; then
		printf " - [✔] Pages are comma-sep'd list ... success.\n"
	else
		printf " - [✗] Pages are comma-sep'd list ... fail. Abort.\n"
		return 1
	fi

	# Check output directory
	if [ -d "$outdir" ] && [ -w "$outdir" ] &&
		outdir="$(realpath "$outdir")"; then
		printf " - [✔] Output directory '%s' is accessible ... success.\n" "$outdir"
	else
		printf " - [✗] Output directory '%s' is accessible ... fail. Abort.\n" "$outdir"
		return 1
	fi

	# Check connection
	if checkconn "$cookies" "$baseurl" >/dev/null; then
		printf " - [✔] Checking connection ... success.\n"
	else
		printf " - [✗] Checking connection ... fail. Abort.\n"
		return 1
	fi

	# Download svg files
	ii=0
	numpgs="$(( 1 + $(echo "$pages" | tr -cd ',' | wc -c) ))"
	goterr=0
	for pgnum in $(echo "$pages" | tr ',' ' '); do
		ii=$((ii + 1))
		if ! _dlsvg "$cookies" "$baseurl" "$outdir" "$pgnum"; then
			goterr=1
		fi
	done

	return "$goterr"
}

_dlsvg() {
	# No input checking; no output statements

	cookies="$1" # path to cookies.txt
	baseurl="$2" # head of url to index.html
	outdir="$3" # directory to dl svg files to
	pgnum="$4" # pages to download as csv

	pageurl="$baseurl/xml/topic${pgnum}.svg"
	svgpath="$outdir/page${pgnum}.svg"

	reply="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" "$pageurl")"
	retcode="$(echo "$reply" | tail -n 1)"
	svg="$(echo "$reply" | head -n -1)"

	if [ -z "$svg" ] || [ ! "$retcode" -eq 200 ]; then
		printf " - [✗] Downloading SVG page %d ... fail.\n" "$pgnum"
		return 1
	else
		printf " - [✔] Downloading SVG page %d ... success.\n" "$pgnum"
		echo "$svg" > "$svgpath"
	fi
}

# Check connection
checkconn() {
	cookies="$1"
	baseurl="$2"

	echo "Checking connection [checkconn]"

	# Assert that cookies.txt exists and is readable
	if [ -z "$cookies" ] || ! cookies="$(realpath "$cookies")" ||
		[ ! -f "$cookies" ] || [ ! -r "$cookies" ]; then
		printf " - [✗] Cookies file '%s' is readable ... fail. Abort.\n" "$cookies"
		return 1
	else
		printf " - [✔] Cookies file '%s' is readable ... success.\n" "$cookies"
	fi

	# Assert that url is sane
	baseurl="$2"
	if [ -z "$baseurl" ]; then
		printf " - [✗] Baseurl '%s' is sane ... fail. Abort.\n" "$baseurl"
		return 1
	else
		printf " - [✔] Baseurl '%s' is sane ... success.\n" "$baseurl"
	fi

	# Attempt to download index.html
	ret=0
	retcode="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" \
		"$baseurl/index.html" | tail -n -1)"
	if [ "$retcode" -eq 200 ]; then
		printf " - [✔] Attempting to download '%s' ... success.\n" "$baseurl/index.html"
	else
		printf " - [✗] Attempting to download '%s'... fail.\n" "$baseurl/index.html"
		ret=1
	fi

	# Attempt to download first page
	retcode="$(curl -Ls -b "$cookies" -c "$cookies" -w "\n%{http_code}" \
		"$baseurl/xml/topic1.svg" | tail -n -1)"
	if [ "$retcode" -eq 200 ]; then
		printf " - [✔] Attempting to download '%s' ... success.\n" "$baseurl/xml/topic.svg"
	else
		printf " - [✗] Attempting to download '%s'... fail.\n" "$baseurl/xml/topic.svg"
		ret=1
	fi
	return "$ret"
}

# Check availability of fonts required by SVG files
checkfonts() {
	svgdir="$1"

	echo "Checking fonts [checkfonts]"

	# Check input directory
	if [ -d "$svgdir" ] && [ -w "$svgdir" ] &&
		svgdir="$(realpath "$svgdir")"; then
		printf " - [✔] Input directory is accessible ... success.\n"
	else
		printf " - [✗] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve svg files in dir
	if svgs="$(find "$svgdir" -maxdepth 1 -mindepth 1 -type f |
		grep '/page[1-9][0-9]*\.svg$')"; then
		numsvgs="$(echo "$svgs" | wc -l)"
		printf " - [✔] Found %d SVG files ... success.\n" "$numsvgs"
	else
		printf " - [✗] No SVG files found ... fail. Abort.\n"
		return 1
	fi

	# Retrieve required and available fonts and compare
	fontsmissing=0
	fontsreq="$(echo "$svgs" | xargs cat | grep -o 'font-family="[^"]*"' |
		cut -d '=' -f 2- | sed -e 's/^"'"'"'\?//g' -e 's/'"'"'\?"$//g' |
		sort | uniq)"
	fontsavail="$(fc-list :family)"
	while read f; do
		if echo "$fontsavail" | grep -q "$f"; then
			printf " - [✔] Font '%s' available.\n" "$f"
		else
			printf " - [✗] Font '%s' not available.\n" "$f"
			fontsmissing=1
		fi
	done <<-EOF
	$fontsreq
	EOF
	return "$fontsmissing"
}

# Generate PDF pages from SVG files
genpdfs() {
	svgdir="$1" # input directory containing page%d.svg files
	pdfdir="$2" # output directory for page%d.pdf files

	echo "Generating PDF pages [genpdfs]"

	# Check input directory
	if [ -d "$svgdir" ] && [ -w "$svgdir" ] &&
		svgdir="$(realpath "$svgdir")"; then
		printf " - [✔] Input directory is accessible ... success.\n"
	else
		printf " - [✗] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Check output directory
	if [ -d "$pdfdir" ] && [ -w "$pdfdir" ] &&
		pdfdir="$(realpath "$pdfdir")"; then
		printf " - [✔] Output directory is accessible ... success.\n"
	else
		printf " - [✗] Output directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve svg files in dir
	if svgs="$(find "$svgdir" -maxdepth 1 -mindepth 1 -type f |
		grep '/page[1-9][0-9]*\.svg$')"; then
		numsvgs="$(echo "$svgs" | wc -l)"
		printf " - [✔] Found %d SVG file(s) ... success.\n" "$numsvgs"
	else
		printf " - [✗] No SVG files found ... fail. Abort.\n"
		return 1
	fi

	ii=0
	goterr=0
	while read svgfile; do
		pdffile="$pdfdir/$(basename -s '.svg' "$svgfile").pdf"
		ii=$((ii + 1))

		if ! _genpdf "$svgdir" "$pdfdir" "$ii"; then
			goterr=1
		fi
	done <<-EOF
	$svgs
	EOF

	return "$goterr"
}

_genpdf() {
	# Unsafe - no checking

	svgdir="$1" # input directory containing page%d.svg files
	pdfdir="$2" # output directory for page%d.pdf files
	pgnum="$3"

	svgfile="$svgdir/page$pgnum.svg"
	pdffile="$pdfdir/page$pgnum.pdf"
	if ! inkscape "$svgfile" --export-pdf="$pdffile" 2>/dev/null; then
		printf " - [✗] Generating SVG page %d ... fail.\n" "$pgnum"
	else
		printf " - [✔] Converting SVG page %d ... success.\n" "$pgnum"
	fi
}

collatepdfs() {
	pdfdir="$1" # input directory containing page%d.png files
	outfile="$2" # output file path for final pdf

	echo "Collating PDF pages [collatepdfs]"

	# Check input directory
	if [ -d "$pdfdir" ] && [ -w "$pdfdir" ] &&
		pdfdir="$(realpath "$pdfdir")"; then
		printf " - [✔] Input directory is accessible ... success.\n"
	else
		printf " - [✗] Input directory is accessible ... fail. Abort.\n"
		return 1
	fi

	# Check output path
	outdir="" # dir containing outfile
	if [ -n "$outfile" ] && outfile="$(realpath "$outfile")" &&
		outdir="$(dirname "$outdir")" && [ -d "$outdir" ] &&
		[ -w "$outdir" ]; then
		printf " - [✔] Output path is accessible ... success.\n"
	else
		printf " - [✗] Output path is accessible ... fail. Abort.\n"
		return 1
	fi

	# Retrieve pdf files in dir (in order)
	if pdfs="$(find "$pdfdir" -maxdepth 1 -mindepth 1 -type f | sort -V |
		grep '/page[1-9][0-9]*\.pdf$')"; then
		numpdfs="$(echo "$pdfs" | wc -l)"
		printf " - [✔] Found %d PDF file(s) ... success.\n" "$numpdfs"
	else
		printf " - [✗] No PDF files found ... fail. Abort.\n"
		return 1
	fi

	# Generate pdf from individual pages
	if echo "$pdfs" | tr '\n' '\0' |
		xargs -0 sh -c 'pdftk "$@" cat output '"$outfile" "$0" 2>/dev/null; then
		printf " - [✔] Generating PDF '$outfile' ... success.\n" "$outfile"
	else
		printf " - [✗] Generating PDF '$outfile' ... fail. Abort.\n" "$outfile"
		return 1
	fi
}

case "$1" in
-h|--help)
	usage
	;;
@)
	shift
	"$@"
	;;
*)
	[ $# -lt 6 ] && { echo "Invalid arguments. See $0 --help."; exit 1; }
	cookies="$1"
	baseurl="$2"
	svgdir="$3"
	pages="$4"
	pdfdir="$5"
	outfile="$6"

	dlsvgs "$cookies" "$baseurl" "$svgdir" "$pages"
	checkfonts "$svgdir"
	genpdfs "$svgdir" "$pdfdir"
	collatepdfs "$pdfdir" "$outfile"
esac

# TODO: Automatically determine pages
#        - Remove page range parameter
# TODO: Unfuck links (SVGs use javascript "links" by default)

# NOTE: We use inkscape for the conversion between SVGs and PDFs.
#       For unknown reasons 'rsvg-convert', which was used prior to that,
#       began to distort the images embedded in the SVGs. inkscape ≥ 1.0 is
#       terminally stupid and cannot execute cli commands without an X
#       server. Thus we're forced to used a dated inkscape version.
#       fixed in inkscape.
